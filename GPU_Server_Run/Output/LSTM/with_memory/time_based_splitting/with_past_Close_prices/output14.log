nohup: ignoring input
2023-12-05 10:42:29.011255: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-05 10:42:29.558301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30686 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:97:00.0, compute capability: 7.0
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
data 
            Date  label_finbert  ...   Adj Close      Volume
4    2019-07-24              1  ...  178.669998  14933100.0
5    2019-07-25              2  ...  177.289993  14049000.0
6    2019-07-30              2  ...  174.100006  14300600.0
7    2019-08-05              2  ...  153.669998  28912600.0
8    2019-08-06              0  ...  157.429993  24996300.0
..          ...            ...  ...         ...         ...
659  2023-10-27              2  ...   82.820000  10795600.0
660  2023-10-30              2  ...   83.139999   8980500.0
661  2023-10-31              0  ...   82.540001  12094300.0
662  2023-11-01              0  ...   82.480003   9550000.0
663  2023-11-02              2  ...   83.410004  10556100.0

[660 rows x 10 columns]
Train indices  range(0, 523)
Test indices  range(523, 655)
4      178.669998
5      177.289993
6      174.100006
7      153.669998
8      157.429993
          ...    
659     82.820000
660     83.139999
661     82.540001
662     82.480003
663     83.410004
Name: Close, Length: 660, dtype: float64
           Open        High         Low   Adj Close      Volume
4    178.000000  178.960007  176.938004  178.669998  14933100.0
5    178.490005  179.149994  175.369003  177.289993  14049000.0
6    174.250000  175.710007  172.889999  174.100006  14300600.0
7    155.029999  157.229996  151.850006  153.669998  28912600.0
8    158.479996  158.729996  156.110001  157.429993  24996300.0
..          ...         ...         ...         ...         ...
659   83.870003   84.120003   82.480003   82.820000  10795600.0
660   83.629997   84.239998   83.011002   83.139999   8980500.0
661   81.940002   82.540001   80.879997   82.540001  12094300.0
662   81.705002   82.489998   81.209999   82.480003   9550000.0
663   83.650002   83.980003   83.029999   83.410004  10556100.0

[660 rows x 5 columns]
     label_distilbert        Open  ...   Adj Close      Volume
4                   1  178.000000  ...  178.669998  14933100.0
5                   2  178.490005  ...  177.289993  14049000.0
6                   2  174.250000  ...  174.100006  14300600.0
7                   0  155.029999  ...  153.669998  28912600.0
8                   0  158.479996  ...  157.429993  24996300.0
..                ...         ...  ...         ...         ...
659                 2   83.870003  ...   82.820000  10795600.0
660                 2   83.629997  ...   83.139999   8980500.0
661                 0   81.940002  ...   82.540001  12094300.0
662                 0   81.705002  ...   82.480003   9550000.0
663                 2   83.650002  ...   83.410004  10556100.0

[660 rows x 6 columns]
     label_finbert        Open        High         Low   Adj Close      Volume
4                1  178.000000  178.960007  176.938004  178.669998  14933100.0
5                2  178.490005  179.149994  175.369003  177.289993  14049000.0
6                2  174.250000  175.710007  172.889999  174.100006  14300600.0
7                2  155.029999  157.229996  151.850006  153.669998  28912600.0
8                0  158.479996  158.729996  156.110001  157.429993  24996300.0
..             ...         ...         ...         ...         ...         ...
659              2   83.870003   84.120003   82.480003   82.820000  10795600.0
660              2   83.629997   84.239998   83.011002   83.139999   8980500.0
661              0   81.940002   82.540001   80.879997   82.540001  12094300.0
662              0   81.705002   82.489998   81.209999   82.480003   9550000.0
663              2   83.650002   83.980003   83.029999   83.410004  10556100.0

[660 rows x 6 columns]
     label_CNN        Open        High         Low   Adj Close      Volume
4            2  178.000000  178.960007  176.938004  178.669998  14933100.0
5            2  178.490005  179.149994  175.369003  177.289993  14049000.0
6            2  174.250000  175.710007  172.889999  174.100006  14300600.0
7            2  155.029999  157.229996  151.850006  153.669998  28912600.0
8            2  158.479996  158.729996  156.110001  157.429993  24996300.0
..         ...         ...         ...         ...         ...         ...
659          2   83.870003   84.120003   82.480003   82.820000  10795600.0
660          2   83.629997   84.239998   83.011002   83.139999   8980500.0
661          2   81.940002   82.540001   80.879997   82.540001  12094300.0
662          2   81.705002   82.489998   81.209999   82.480003   9550000.0
663          2   83.650002   83.980003   83.029999   83.410004  10556100.0

[660 rows x 6 columns]
0      177.289993
1      174.100006
2      153.669998
3      157.429993
4      157.429993
          ...    
654     82.820000
655     83.139999
656     82.540001
657     82.480003
658     83.410004
Name: Close, Length: 659, dtype: float64
           Open        High         Low   Adj Close      Volume       Close
0    178.000000  178.960007  176.938004  178.669998  14933100.0  177.289993
1    178.490005  179.149994  175.369003  177.289993  14049000.0  174.100006
2    174.250000  175.710007  172.889999  174.100006  14300600.0  153.669998
3    155.029999  157.229996  151.850006  153.669998  28912600.0  157.429993
4    158.479996  158.729996  156.110001  157.429993  24996300.0  157.429993
..          ...         ...         ...         ...         ...         ...
654   82.959999   83.730003   82.760002   83.010002   9321600.0   82.820000
655   83.870003   84.120003   82.480003   82.820000  10795600.0   83.139999
656   83.629997   84.239998   83.011002   83.139999   8980500.0   82.540001
657   81.940002   82.540001   80.879997   82.540001  12094300.0   82.480003
658   81.705002   82.489998   81.209999   82.480003   9550000.0   83.410004

[659 rows x 6 columns]
     label_distilbert        Open  ...      Volume       Close
0                 1.0  178.000000  ...  14933100.0  177.289993
1                 2.0  178.490005  ...  14049000.0  174.100006
2                 2.0  174.250000  ...  14300600.0  153.669998
3                 0.0  155.029999  ...  28912600.0  157.429993
4                 0.0  158.479996  ...  24996300.0  157.429993
..                ...         ...  ...         ...         ...
654               2.0   82.959999  ...   9321600.0   82.820000
655               2.0   83.870003  ...  10795600.0   83.139999
656               2.0   83.629997  ...   8980500.0   82.540001
657               0.0   81.940002  ...  12094300.0   82.480003
658               0.0   81.705002  ...   9550000.0   83.410004

[659 rows x 7 columns]
     label_finbert        Open        High  ...   Adj Close      Volume       Close
0              1.0  178.000000  178.960007  ...  178.669998  14933100.0  177.289993
1              2.0  178.490005  179.149994  ...  177.289993  14049000.0  174.100006
2              2.0  174.250000  175.710007  ...  174.100006  14300600.0  153.669998
3              2.0  155.029999  157.229996  ...  153.669998  28912600.0  157.429993
4              0.0  158.479996  158.729996  ...  157.429993  24996300.0  157.429993
..             ...         ...         ...  ...         ...         ...         ...
654            2.0   82.959999   83.730003  ...   83.010002   9321600.0   82.820000
655            2.0   83.870003   84.120003  ...   82.820000  10795600.0   83.139999
656            2.0   83.629997   84.239998  ...   83.139999   8980500.0   82.540001
657            0.0   81.940002   82.540001  ...   82.540001  12094300.0   82.480003
658            0.0   81.705002   82.489998  ...   82.480003   9550000.0   83.410004

[659 rows x 7 columns]
     label_CNN        Open        High  ...   Adj Close      Volume       Close
0          2.0  178.000000  178.960007  ...  178.669998  14933100.0  177.289993
1          2.0  178.490005  179.149994  ...  177.289993  14049000.0  174.100006
2          2.0  174.250000  175.710007  ...  174.100006  14300600.0  153.669998
3          2.0  155.029999  157.229996  ...  153.669998  28912600.0  157.429993
4          2.0  158.479996  158.729996  ...  157.429993  24996300.0  157.429993
..         ...         ...         ...  ...         ...         ...         ...
654        2.0   82.959999   83.730003  ...   83.010002   9321600.0   82.820000
655        2.0   83.870003   84.120003  ...   82.820000  10795600.0   83.139999
656        2.0   83.629997   84.239998  ...   83.139999   8980500.0   82.540001
657        2.0   81.940002   82.540001  ...   82.540001  12094300.0   82.480003
658        2.0   81.705002   82.489998  ...   82.480003   9550000.0   83.410004

[659 rows x 7 columns]
           Open        High         Low  ...   Close t-2   Close t-3   Close t-4
4    158.479996  158.729996  156.110001  ...  153.669998  174.100006  177.289993
5    158.479996  158.729996  156.110001  ...  157.429993  153.669998  174.100006
6    157.500000  159.360001  155.539993  ...  157.429993  157.429993  153.669998
7    160.639999  167.360001  159.570007  ...  159.309998  157.429993  157.429993
8    161.339996  163.000000  159.210007  ...  164.029999  159.309998  157.429993
..          ...         ...         ...  ...         ...         ...         ...
654   82.959999   83.730003   82.760002  ...   83.910004   84.309998   84.019997
655   83.870003   84.120003   82.480003  ...   83.010002   83.910004   84.309998
656   83.629997   84.239998   83.011002  ...   82.820000   83.010002   83.910004
657   81.940002   82.540001   80.879997  ...   83.139999   82.820000   83.010002
658   81.705002   82.489998   81.209999  ...   82.540001   83.139999   82.820000

[655 rows x 29 columns]
     label_distilbert        Open  ...   Close t-3   Close t-4
4                 0.0  158.479996  ...  174.100006  177.289993
5                 2.0  158.479996  ...  153.669998  174.100006
6                 2.0  157.500000  ...  157.429993  153.669998
7                 2.0  160.639999  ...  157.429993  157.429993
8                 2.0  161.339996  ...  159.309998  157.429993
..                ...         ...  ...         ...         ...
654               2.0   82.959999  ...   84.309998   84.019997
655               2.0   83.870003  ...   83.910004   84.309998
656               2.0   83.629997  ...   83.010002   83.910004
657               0.0   81.940002  ...   82.820000   83.010002
658               0.0   81.705002  ...   83.139999   82.820000

[655 rows x 34 columns]
     label_finbert        Open        High  ...   Close t-2   Close t-3   Close t-4
4              0.0  158.479996  158.729996  ...  153.669998  174.100006  177.289993
5              2.0  158.479996  158.729996  ...  157.429993  153.669998  174.100006
6              1.0  157.500000  159.360001  ...  157.429993  157.429993  153.669998
7              2.0  160.639999  167.360001  ...  159.309998  157.429993  157.429993
8              0.0  161.339996  163.000000  ...  164.029999  159.309998  157.429993
..             ...         ...         ...  ...         ...         ...         ...
654            2.0   82.959999   83.730003  ...   83.910004   84.309998   84.019997
655            2.0   83.870003   84.120003  ...   83.010002   83.910004   84.309998
656            2.0   83.629997   84.239998  ...   82.820000   83.010002   83.910004
657            0.0   81.940002   82.540001  ...   83.139999   82.820000   83.010002
658            0.0   81.705002   82.489998  ...   82.540001   83.139999   82.820000

[655 rows x 34 columns]
     label_CNN        Open        High  ...   Close t-2   Close t-3   Close t-4
4          2.0  158.479996  158.729996  ...  153.669998  174.100006  177.289993
5          2.0  158.479996  158.729996  ...  157.429993  153.669998  174.100006
6          2.0  157.500000  159.360001  ...  157.429993  157.429993  153.669998
7          2.0  160.639999  167.360001  ...  159.309998  157.429993  157.429993
8          2.0  161.339996  163.000000  ...  164.029999  159.309998  157.429993
..         ...         ...         ...  ...         ...         ...         ...
654        2.0   82.959999   83.730003  ...   83.910004   84.309998   84.019997
655        2.0   83.870003   84.120003  ...   83.010002   83.910004   84.309998
656        2.0   83.629997   84.239998  ...   82.820000   83.010002   83.910004
657        2.0   81.940002   82.540001  ...   83.139999   82.820000   83.010002
658        2.0   81.705002   82.489998  ...   82.540001   83.139999   82.820000

[655 rows x 34 columns]
Second index resetting
0      177.289993
1      174.100006
2      153.669998
3      157.429993
4      157.429993
          ...    
654     82.820000
655     83.139999
656     82.540001
657     82.480003
658     83.410004
Name: Close, Length: 659, dtype: float64
           Open        High         Low  ...   Close t-2   Close t-3   Close t-4
0    158.479996  158.729996  156.110001  ...  153.669998  174.100006  177.289993
1    158.479996  158.729996  156.110001  ...  157.429993  153.669998  174.100006
2    157.500000  159.360001  155.539993  ...  157.429993  157.429993  153.669998
3    160.639999  167.360001  159.570007  ...  159.309998  157.429993  157.429993
4    161.339996  163.000000  159.210007  ...  164.029999  159.309998  157.429993
..          ...         ...         ...  ...         ...         ...         ...
650   82.959999   83.730003   82.760002  ...   83.910004   84.309998   84.019997
651   83.870003   84.120003   82.480003  ...   83.010002   83.910004   84.309998
652   83.629997   84.239998   83.011002  ...   82.820000   83.010002   83.910004
653   81.940002   82.540001   80.879997  ...   83.139999   82.820000   83.010002
654   81.705002   82.489998   81.209999  ...   82.540001   83.139999   82.820000

[655 rows x 29 columns]
     label_distilbert        Open  ...   Close t-3   Close t-4
0                 0.0  158.479996  ...  174.100006  177.289993
1                 2.0  158.479996  ...  153.669998  174.100006
2                 2.0  157.500000  ...  157.429993  153.669998
3                 2.0  160.639999  ...  157.429993  157.429993
4                 2.0  161.339996  ...  159.309998  157.429993
..                ...         ...  ...         ...         ...
650               2.0   82.959999  ...   84.309998   84.019997
651               2.0   83.870003  ...   83.910004   84.309998
652               2.0   83.629997  ...   83.010002   83.910004
653               0.0   81.940002  ...   82.820000   83.010002
654               0.0   81.705002  ...   83.139999   82.820000

[655 rows x 34 columns]
     label_finbert        Open        High  ...   Close t-2   Close t-3   Close t-4
0              0.0  158.479996  158.729996  ...  153.669998  174.100006  177.289993
1              2.0  158.479996  158.729996  ...  157.429993  153.669998  174.100006
2              1.0  157.500000  159.360001  ...  157.429993  157.429993  153.669998
3              2.0  160.639999  167.360001  ...  159.309998  157.429993  157.429993
4              0.0  161.339996  163.000000  ...  164.029999  159.309998  157.429993
..             ...         ...         ...  ...         ...         ...         ...
650            2.0   82.959999   83.730003  ...   83.910004   84.309998   84.019997
651            2.0   83.870003   84.120003  ...   83.010002   83.910004   84.309998
652            2.0   83.629997   84.239998  ...   82.820000   83.010002   83.910004
653            0.0   81.940002   82.540001  ...   83.139999   82.820000   83.010002
654            0.0   81.705002   82.489998  ...   82.540001   83.139999   82.820000

[655 rows x 34 columns]
     label_CNN        Open        High  ...   Close t-2   Close t-3   Close t-4
0          2.0  158.479996  158.729996  ...  153.669998  174.100006  177.289993
1          2.0  158.479996  158.729996  ...  157.429993  153.669998  174.100006
2          2.0  157.500000  159.360001  ...  157.429993  157.429993  153.669998
3          2.0  160.639999  167.360001  ...  159.309998  157.429993  157.429993
4          2.0  161.339996  163.000000  ...  164.029999  159.309998  157.429993
..         ...         ...         ...  ...         ...         ...         ...
650        2.0   82.959999   83.730003  ...   83.910004   84.309998   84.019997
651        2.0   83.870003   84.120003  ...   83.010002   83.910004   84.309998
652        2.0   83.629997   84.239998  ...   82.820000   83.010002   83.910004
653        2.0   81.940002   82.540001  ...   83.139999   82.820000   83.010002
654        2.0   81.705002   82.489998  ...   82.540001   83.139999   82.820000

[655 rows x 34 columns]
X_train_no_SA 
 [[0.38379118 0.37647199 0.39389682 ... 0.36545682 0.44793898 0.46081793]
 [0.38379118 0.37647199 0.39389682 ... 0.38063706 0.36545682 0.44793898]
 [0.37984372 0.37897838 0.39160809 ... 0.38063706 0.38063706 0.36545682]
 ...
 [0.09610891 0.1000955  0.11487655 ... 0.11050101 0.09201018 0.09201018]
 [0.11588658 0.12028565 0.1327846  ... 0.10165934 0.11050101 0.09201018]
 [0.10831385 0.10657623 0.11941378 ... 0.12523718 0.10165934 0.11050101]]
y_train 
 0      177.289993
1      174.100006
2      153.669998
3      157.429993
4      157.429993
          ...    
518     79.860001
519     87.559998
520     85.940002
521     85.940002
522     90.519997
Name: Close, Length: 523, dtype: float64
Shape X_train_no_SA: (523, 29)
Shape X_test_no_SA: (132, 29)
Shape y_train: (523,)
Shape y_test: (132,)
Shape X_train_no_SA: (523, 29)
Shape X_test_no_SA: (132, 29)
Shape y_train: (523,)
Shape y_test: (132,)
Shape X_train_reshaped: (523, 1, 29)
Shape X_test_reshaped: (132, 1, 29)
Shape y_train_reshaped: (523, 1, 1)
Shape X_train_tensor: (523, 1, 29)
Shape X_test_tensor: (132, 1, 29)
Shape y_train_tensor: (523, 1, 1)
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 50)                16000     
                                                                 
 dense (Dense)               (None, 1)                 51        
                                                                 
=================================================================
Total params: 16,051
Trainable params: 16,051
Non-trainable params: 0
_________________________________________________________________
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[48.820286 48.333218 48.12883  46.318268 54.567642 62.50872  70.25137
 79.121544 85.867455 87.095436 87.9693   86.19049  84.35209  85.19618
 85.27279  83.549255 81.09349  78.562584 73.887726 69.819786 68.60878
 68.11364  67.66273  68.184494 67.190285 65.97883  64.62798  63.197273
 61.670803 61.30399  62.22614  61.071728 58.06841  57.393425 55.40395
 50.885548 47.70144  47.581715 44.21366  57.806347 64.629295 73.97322
 78.66459  82.7324   72.71678  69.49695  63.683037 59.719063 58.232708
 54.1164   47.141758 45.043873 42.8211   39.925537 40.615524 44.43125
 48.757336 48.31371  47.832737 46.5774   43.193165 36.50253  34.844986
 32.92091  33.129063 32.908737 33.60933  34.844753 37.166954 40.31011
 44.650375 46.67722  47.248905 45.94325  43.086483 39.87244  37.28827
 35.9257   40.837112 43.216946 45.749466 50.815037 54.583057 52.177814
 51.752747 51.001396 51.958733 53.20959  54.123196 56.853016 58.328148
 57.22724  54.86755  60.09475  59.66902  58.583935 56.888752 56.43513
 49.810917 46.856327 44.74031  44.86717  45.33696  45.685413 46.36892
 47.76992  47.708496 45.827747 44.53023  43.62521  42.08656  40.340546
 39.670483 39.041435 37.59176  37.01488  35.94188  37.626225 37.305653
 37.213074 36.94863  37.47124  34.82456  35.35406  34.820217 34.502426
 33.497227 33.109226 32.023067 31.612314 31.33501  31.130154]
capital_evolution_true shape (131, 1)
capital_evolution_no_SA shape (131,)
Shape X_train_finbert: (523, 34)
Shape X_test_finbert: (132, 34)
Shape X_train_finbert: (523, 34)
Shape X_test_finbert: (132, 34)
Shape X_train_reshaped: (523, 1, 34)
Shape X_test_reshaped: (132, 1, 34)
Shape X_train_tensor: (523, 1, 34)
Shape X_test_tensor: (132, 1, 34)
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_1 (LSTM)               (None, 50)                17000     
                                                                 
 dense_1 (Dense)             (None, 1)                 51        
                                                                 
=================================================================
Total params: 17,051
Trainable params: 17,051
Non-trainable params: 0
_________________________________________________________________
WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[ 82.59954   75.001236  74.5289    72.63949   79.16415   86.1592
  92.44222   99.30378  110.86745  105.22659  107.619644 106.916306
  91.02655   78.01814   92.79335   96.84302   93.78603   99.607765
 110.106964  99.37609   91.521835  98.53766   97.629005  91.10853
  97.73611   96.19462   94.94392   93.97166   92.86779   86.05537
  93.37363   91.44588   81.77009   89.04145   87.37733   83.012146
  80.44123   93.802246  84.54628   95.46136  101.30345  100.93261
  97.778305 101.818565  94.43462   84.86542   80.38589   77.26703
  75.981384  79.42614   66.46992   65.09959   63.78274   60.594875
  54.02128   71.35637   74.21064   67.0715    67.68792   59.460144
  56.10605   57.27877   55.181995  61.590714  62.333214  54.695915
  42.095943  43.101612  38.437458  40.61443   36.988037  45.947598
  59.88131   57.7158    55.78887   61.556545  52.404095  50.60022
  54.13258   62.73786   72.446175  89.982346  78.809746  85.24528
  91.812996  76.26875   70.92599   86.67069   79.1122    74.22137
  76.424904  76.08863   59.895374  63.52779   70.21021   82.285
  80.46839   94.722626  96.660385  93.61437   91.90176   85.590805
  80.13495   66.87669   59.864292  60.750725  59.888596  65.80837
  72.27899   77.7228    69.47378   75.38587   68.24846   67.70031
  59.216633  65.7013    57.394833  66.09246   73.01581   71.81473
  72.05575   79.989815  70.6827    64.545204  64.06836   63.388836
  69.0431    75.23008   81.47324   88.236015  74.31635   61.05809 ]
capital_evolution_finbert shape (131,)
Shape X_train_distilbert: (523, 34)
Shape X_test_distilbert: (132, 34)
Shape X_train_distilbert: (523, 34)
Shape X_test_distilbert: (132, 34)
Shape X_train_reshaped: (523, 1, 34)
Shape X_test_reshaped: (132, 1, 34)
Shape X_train_tensor: (523, 1, 34)
Shape X_test_tensor: (132, 1, 34)
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_2 (LSTM)               (None, 50)                17000     
                                                                 
 dense_2 (Dense)             (None, 1)                 51        
                                                                 
=================================================================
Total params: 17,051
Trainable params: 17,051
Non-trainable params: 0
_________________________________________________________________
WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
[ 95.87664   94.91419   94.87956   93.47764   99.76849  112.35374
 118.67173  114.53223  119.099    120.19264  121.13412  108.34022
 106.75932   94.69397   94.07169   80.498055  78.38607   82.24835
  78.75161   68.22486   67.53607   79.58804   85.73799   87.06648
  79.51521   90.58137   77.49427   62.918842  67.77229   68.026344
  55.285896  66.86391   65.30957   70.192604  75.41256   78.41156
  75.1639    87.95324   79.28505   95.586205  96.3015    97.43432
  94.63471   98.45536   89.63081   87.82673   88.637566  91.86725
  96.89409   93.47081   88.675865  85.84799   77.85568   69.039444
  62.87867   72.805016  63.507504  56.84759   62.198162  55.165253
  45.749672  39.92412   38.728428  24.983734  36.466988  49.316685
  50.562347  51.52255   66.12206   56.58619   47.006283  54.927906
  68.44542   54.820683  52.181446  49.439503  40.86397   27.362648
  31.042044  39.06253   53.975475  71.273056  75.35485   73.28701
  66.30398   52.578773  52.477074  54.385403  61.512577  76.3847
  78.64927   76.842255  75.76093   85.47424   73.09984   72.358345
  57.290222  57.109646  38.458015  36.06122   34.326733  40.46663
  53.528687  54.676544  67.67269   69.68345   63.006634  48.017677
  53.37218   52.08885   57.860336  62.889324  62.603676  67.9427
  60.534283  53.753292  58.490013  73.21564   60.669872  59.979877
  72.5831    73.23362   64.63452   77.75674   83.81564   71.311104
  69.50492   75.74848   74.898125  74.41656   74.93963   61.48421 ]
capital_evolution_distilbert shape (131,)
Shape X_train_CNN: (523, 34)
Shape X_test_CNN: (132, 34)
Shape X_train_CNN: (523, 34)
Shape X_test_CNN: (132, 34)
Shape X_train_reshaped: (523, 1, 34)
Shape X_test_reshaped: (132, 1, 34)
Shape X_train_tensor: (523, 1, 34)
Shape X_test_tensor: (132, 1, 34)
Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_3 (LSTM)               (None, 50)                17000     
                                                                 
 dense_3 (Dense)             (None, 1)                 51        
                                                                 
=================================================================
Total params: 17,051
Trainable params: 17,051
Non-trainable params: 0
_________________________________________________________________
[48.68266  48.061    47.94755  46.09962  54.287315 62.36513  70.32898
 79.32454  86.20159  87.29044  87.97412  86.14354  84.20399  85.00618
 85.04642  83.29997  80.84226  78.29106  73.58199  69.50701  68.23924
 67.73788  67.33884  67.84769  66.889114 65.662796 64.291626 62.860493
 61.329838 61.00145  61.885998 60.85038  57.97312  57.295216 55.390633
 50.879013 47.60714  47.40654  44.00733  57.403374 64.70845  74.494965
 79.250305 83.47703  72.91628  69.50418  63.54873  59.608047 58.02893
 53.926105 46.96301  44.75956  42.58609  39.798016 40.42643  44.24143
 48.485283 48.27389  47.881535 46.598885 43.21397  36.36871  34.71791
 32.794277 32.974205 32.761494 33.42945  34.61266  36.893456 39.980476
 44.3683   46.47823  47.10202  45.797333 42.896328 39.640976 37.053925
 35.689342 40.49033  42.984768 45.652195 50.673603 54.53011  51.998077
 51.513508 50.764214 51.6238   52.945473 53.951828 56.618725 58.14761
 56.96422  54.57382  59.74151  59.474487 58.5287   56.775528 56.341232
 49.563995 46.589928 44.500275 44.62456  45.018597 45.4068   46.046688
 47.44088  47.356186 45.498917 44.197166 43.26346  41.772865 40.022423
 39.353054 38.724125 37.26534  36.686756 35.616943 37.27429  37.008472
 36.97157  36.686768 37.19288  34.51686  35.033188 34.51163  34.231808
 33.23066  32.85154  31.749428 31.350075 31.078907 30.887527]
capital_evolution_CNN shape (131,)
ret_true shape (131, 1)
<style type="text/css">
#T_fd8ec_row0_col0 {
  background-color: hsl(0, 50%, 132.37973533351814%);
  color: darkred;
}
#T_fd8ec_row1_col0, #T_fd8ec_row4_col0 {
  background-color: hsl(0, 50%, 174.77580058681335%);
  color: darkred;
}
#T_fd8ec_row2_col0, #T_fd8ec_row3_col0 {
  background-color: hsl(120, 50%, 0%);
  color: darkgreen;
}
</style>
<table id="T_fd8ec_">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th class="col_heading level0 col0" >Total returns</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_fd8ec_level0_row0" class="row_heading level0 row0" >Long only</th>
      <td id="T_fd8ec_row0_col0" class="data row0 col0" >-6.24%</td>
    </tr>
    <tr>
      <th id="T_fd8ec_level0_row1" class="row_heading level0 row1" >LSTM no SA</th>
      <td id="T_fd8ec_row1_col0" class="data row1 col0" >-10.48%</td>
    </tr>
    <tr>
      <th id="T_fd8ec_level0_row2" class="row_heading level0 row2" >LSTM finbert</th>
      <td id="T_fd8ec_row2_col0" class="data row2 col0" >114.12%</td>
    </tr>
    <tr>
      <th id="T_fd8ec_level0_row3" class="row_heading level0 row3" >LSTM distilbert</th>
      <td id="T_fd8ec_row3_col0" class="data row3 col0" >100.52%</td>
    </tr>
    <tr>
      <th id="T_fd8ec_level0_row4" class="row_heading level0 row4" >LSTM CNN</th>
      <td id="T_fd8ec_row4_col0" class="data row4 col0" >-10.48%</td>
    </tr>
  </tbody>
</table>

